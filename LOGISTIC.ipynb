{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJhNMOamzZ8IOYdrMsFtGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhashgampa1/Machine_Learning/blob/main/LOGISTIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdG2maSsRRiR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "PXsBJscqxILP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "oPWF2GkZxLEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbe960ca",
        "outputId": "5dc81508-56c8-4ba9-a996-9a6a12b1c947"
      },
      "source": [
        "# Replace 'your_file.zip' with the actual path to your zip file\n",
        "!unzip /content/archive\\ \\(2\\).zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/archive (2).zip\n",
            "replace spam_or_not_spam.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/spam_or_not_spam.csv')"
      ],
      "metadata": {
        "id": "pcKldyANx0nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "#NLP\n",
        "# Fill NaN values in the 'email' column with an empty string\n",
        "df['email'] = df['email'].fillna('')\n",
        "# Feature extraction with bigrams\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 2))  # Use both unigrams and bigrams\n",
        "X = vectorizer.fit_transform(df['email'])\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "CdKEJdGxyDdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "XKxjF8m1TSxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWWvq-NIzp-i",
        "outputId": "9bca4879-24ff-4aa1-ed97-b715e3401bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=3200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiUa7Q4EUXwy",
        "outputId": "ca538bc7-ed48-44be-9bcc-498cb9ff0646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "    # Transform input text using the same vectorizer\n",
        "    input_data = vectorizer.transform([text])\n",
        "\n",
        "    # Predict using the logistic regression model\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Map prediction to class label\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Not Spam\"\n",
        "\n",
        "# Create and launch Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter email content here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Email Spam Detector\",\n",
        "    description=\"Enter the content of an email to classify it as Spam or Not Spam.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app in Colab\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "G0oGEcQoUz3m",
        "outputId": "b53e6fb7-a7f9-40f4-e8b6-0d4aca2b85f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://21c7e8abbcb973a9d0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://21c7e8abbcb973a9d0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7679d38e"
      },
      "source": [
        "IMPROVING MODEL ACCURACY\n",
        "\n",
        "### 1. Feature Engineering: Trying a wider N-gram Range\n",
        "\n",
        "Let's try using unigrams, bigrams, and trigrams (`ngram_range=(1, 3)`) with `CountVectorizer` to capture more context in the text. We will then retrain and re-evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77c879bd",
        "outputId": "f4c3c11b-b512-4c61-9cb8-0cbc2cf135a2"
      },
      "source": [
        "# Feature extraction with unigrams, bigrams, and trigrams\n",
        "vectorizer_1_3 = CountVectorizer(ngram_range=(1, 3))\n",
        "X_1_3 = vectorizer_1_3.fit_transform(df['email'])\n",
        "\n",
        "# Split data again with new features\n",
        "X_train_1_3, X_test_1_3, y_train_1_3, y_test_1_3 = train_test_split(X_1_3, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Train and evaluate model with new features\n",
        "model_1_3 = LogisticRegression(max_iter=3200)\n",
        "model_1_3.fit(X_train_1_3, y_train_1_3)\n",
        "\n",
        "y_pred_1_3 = model_1_3.predict(X_test_1_3)\n",
        "accuracy_1_3 = accuracy_score(y_test_1_3, y_pred_1_3)\n",
        "\n",
        "print(f\"Model Accuracy with N-grams (1,3): {accuracy_1_3:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with N-grams (1,3): 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "    # Transform input text using the same vectorizer\n",
        "    input_data = vectorizer_1_3.transform([text])\n",
        "\n",
        "    # Predict using the logistic regression model\n",
        "    prediction = model_1_3.predict(input_data)\n",
        "\n",
        "    # Map prediction to class label\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Not Spam\"\n",
        "\n",
        "# Create and launch Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter email content here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Email Spam Detector With Vectorization 1_3\",\n",
        "    description=\"Enter the content of an email to classify it as Spam or Not Spam.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app in Colab\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "9a56ac05-6923-4670-b37b-a40137eab0ec",
        "id": "imE0WA-32yup"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e69874cf6eee3a201e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e69874cf6eee3a201e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78d2190a"
      },
      "source": [
        "### 1.2 Feature Engineering: Using TF-IDF Vectorizer\n",
        "\n",
        "Instead of just counting word occurrences, TF-IDF (Term Frequency-Inverse Document Frequency) gives more weight to words that are unique to a document but less common across all documents. This can sometimes provide better feature representations for text classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0feb96df",
        "outputId": "8eb048dd-b9e2-480f-f4c2-142b044272b3"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Feature extraction with TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2)) # Using default (1,2) ngrams for TF-IDF as well\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['email'])\n",
        "\n",
        "# Split data again with new features\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Train and evaluate model with TF-IDF features\n",
        "model_tfidf = LogisticRegression(max_iter=3200)\n",
        "model_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
        "accuracy_tfidf = accuracy_score(y_test_tfidf, y_pred_tfidf)\n",
        "\n",
        "print(f\"Model Accuracy with TF-IDF: {accuracy_tfidf:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with TF-IDF: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "    # Transform input text using the same vectorizer\n",
        "    input_data = tfidf_vectorizer.transform([text])\n",
        "\n",
        "    # Predict using the logistic regression model\n",
        "    prediction = model_tfidf.predict(input_data)\n",
        "\n",
        "    # Map prediction to class label\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Not Spam\"\n",
        "\n",
        "# Create and launch Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter email content here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Email Spam Detector With TF-IDF\",\n",
        "    description=\"Enter the content of an email to classify it as Spam or Not Spam.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app in Colab\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "378c44e3-36e8-4ea9-e65f-b88dd108423c",
        "id": "j8Wmf3455Pxe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9aea6eda7b54fd50db.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9aea6eda7b54fd50db.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447f9d37"
      },
      "source": [
        "### 2. Hyperparameter Tuning: Optimizing 'C' for Logistic Regression\n",
        "\n",
        "The `C` parameter in Logistic Regression is the inverse of regularization strength. Smaller values specify stronger regularization. We'll use `GridSearchCV` to systematically search for the best `C` value that maximizes accuracy. We will use the original `CountVectorizer` features (`X_train`, `X_test`) for this tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "891a4a18",
        "outputId": "564a7482-9b6e-4cc2-8e46-7621c47bd20d"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=3200)\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train) # Using original X_train, y_train from CountVectorizer(1,2)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_tuned = best_model.predict(X_test)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"Test set accuracy with tuned C: {accuracy_tuned:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 1}\n",
            "Best cross-validation accuracy: 0.99\n",
            "Test set accuracy with tuned C: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tuned_model(text):\n",
        "    # Transform input text using the original vectorizer (from CountVectorizer(1,2))\n",
        "    input_data = vectorizer.transform([text])\n",
        "\n",
        "    # Predict using the best model found by GridSearchCV\n",
        "    prediction = best_model.predict(input_data)\n",
        "\n",
        "    # Map prediction to class label\n",
        "    return \"Spam\" if prediction[0] == 1 else \"Not Spam\"\n",
        "\n",
        "# Create and launch Gradio interface for the tuned model\n",
        "interface_tuned = gr.Interface(\n",
        "    fn=predict_tuned_model,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter email content here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Email Spam Detector (C-Tuned Model)\",\n",
        "    description=\"Enter the content of an email to classify it as Spam or Not Spam using the C-tuned Logistic Regression model.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app in Colab\n",
        "interface_tuned.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "nB65_N558k_U",
        "outputId": "f7f06cf3-929a-4950-8527-57f6e4f1b5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cfc3613ed338dd82ba.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cfc3613ed338dd82ba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}